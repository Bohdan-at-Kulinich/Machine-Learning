{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMtg949tORgxeio4VKrgoed",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bohdan-at-Kulinich/Machine-Learning/blob/main/Multiclass_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Single-label multiclass classification\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "fDrtLAo_QpEN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loadin Reuters dataset: \n",
        "\n",
        "from tensorflow.keras.datasets import reuters\n",
        "(train_data, train_labels), (test_data, test_labels) = reuters.load_data(num_words=10000) \n",
        "\n",
        "# restrict the data to the 10,000 most frequently occuring words found in the data "
      ],
      "metadata": {
        "id": "qTg7WctEQwbm"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(tain_data) # number of training examples "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LJVLOjJwRWNs",
        "outputId": "03b0eacb-4112-41ed-e795-a97ef2baa0d2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8982"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(test_data) # number of test examples "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qedtSNu6RcZV",
        "outputId": "be2aaca4-3cb4-40a4-fe46-129227051e4d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2246"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# each example is a list of integers:\n",
        "\n",
        "train_data[10] "
      ],
      "metadata": {
        "id": "1P2zV9xJRlrr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# decoding newswires back to text: \n",
        "word_index = reuters.get_word_index() # dictionary {word : index} \n",
        "reverse_word_index = dict( \n",
        "    [(value, key) for (key, value) in word_index.items()]) # dictionary {index: word}\n",
        "decoded_newswire = \" \".join(\n",
        "    [reverse_word_index.get(i-3, \"?\") for i in train_data[10]]) \n",
        "\n",
        "# offset the indices by 3, since 0, 1, 2 are reserved for 'padding', 'start sequence', and 'unknown'. "
      ],
      "metadata": {
        "id": "qhq1XH5NRzUd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# the labels associated with an example is an integer between 0 and 45: \n",
        "\n",
        "train_labels[10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16ErYQm8SKl2",
        "outputId": "2bd40dc3-5f13-47cf-eae6-051818a52748"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preparing the data "
      ],
      "metadata": {
        "id": "vo2DO4bUT4l6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encoding the input data: \n",
        "# vectorize the data via muli-hot encoding\n",
        "\n",
        "import numpy as np \n",
        "\n",
        "def vectorize_sequence(sequences, dimension=10000):\n",
        "  results = np.zeros((len(sequences), dimension)) # create an all-zero matrix \n",
        "  for i, sequence in enumerate(sequences):\n",
        "    for j in sequence:\n",
        "      results[i, j] = 1.  # sets specific indices of results[i] to 1 \n",
        "  return results \n",
        "\n",
        "x_train = vectorize_sequence(train_data)\n",
        "x_test = vectorize_sequence(test_data) \n"
      ],
      "metadata": {
        "id": "Ns-yO4nKT6tT"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encoding hte labels: \n",
        "# one-hot encoding for categorical data = categorical encoding\n",
        "# embedding each label as an all-zero vector with 1 in place of the label index\n",
        "\n",
        "def to_one_hot(labels, dimension=46):\n",
        "  results = np.zeros((len(labels), dimension))\n",
        "  for i, label in enumerate(labels):\n",
        "    results[i, label] = 1. \n",
        "  return results \n",
        "\n",
        "y_train = to_one_hot(train_labels)\n",
        "y_test = to_one_hot(test_labels) "
      ],
      "metadata": {
        "id": "FZ6L6Jd7VPaS"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The built-in way of doing one-hot encoding in Keras:\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical \n",
        "y_train = to_categorical(train_labels)\n",
        "y_test = to_categorical(test_labels) "
      ],
      "metadata": {
        "id": "DkLFHgUtWNYW"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model building "
      ],
      "metadata": {
        "id": "VAFv9VWqYA7m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# since the number of output classes is big (46), to prevent the information bottleneck\n",
        "# which cab be potentially generated if the dimensionality of the Dense layers is too small, \n",
        "# we need to increase the number of Dense units to 64\n",
        "\n",
        "from tensorflow import keras \n",
        "from tensorflow.keras import layers \n",
        "\n",
        "model = keras.Sequential([\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(46, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "xDKZ8MdbYD_s"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gfj5IC0_ZF4f"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}