{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPZ8tKPAyeOSOmZudEziy2z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bohdan-at-Kulinich/Machine-Learning/blob/main/Evaluating_models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Simple holdout validation "
      ],
      "metadata": {
        "id": "_R-ijqiK49Yh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set apart some fraction of the data as a test set. \n",
        "# Train on the ramaining set. \n",
        "# To prevent information leaks, don't tune your model on the test set, \n",
        "# researve a validation set instead:\n",
        "\n",
        "num_validation_samples = 10000\n",
        "\n",
        "# shuffling the data is usually appropriate:\n",
        "np.random.shuffle(data) \n",
        "\n",
        "# define the validation set:\n",
        "validation_data = data[:num_validation_samples] \n",
        "\n",
        "# define the training set:\n",
        "training_data = data[num_validation_samples:]\n",
        "\n",
        "# traine a model on the training data, and evaluate it on the validation data:\n",
        "model = get_model()\n",
        "model.fit(training_data, ...)\n",
        "validation_score = model.evaluate(validation_data, ...) \n",
        "\n",
        "# tune the model, retrain it, evaluate it, tune it again... \n",
        "\n",
        "# after tunings all the hyperparameters, train the final model from scratch \n",
        "# on all non-test data available:\n",
        "model = get_model()\n",
        "model.fit(np.concatenate([training_data, \n",
        "                          validation_data]), ...)\n",
        "test_score = model.evaluate(test_data, ...) \n",
        "\n",
        "# If little data is available, then the validation and test sets may contain \n",
        "# too few samples be statistically representative of the whole dataset. "
      ],
      "metadata": {
        "id": "YijW4KPL5Cr8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### K-fold validation"
      ],
      "metadata": {
        "id": "jLsGWdDj74-j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into K partitions of equal size. \n",
        "# For each partition i, train a model on the remaining K-1 partitions,\n",
        "# and evaluate it on partition i. \n",
        "# The final score is the averages of the K scores obtained. \n",
        "\n",
        "k = 3\n",
        "num_validation_samples = len(data) // k \n",
        "np.random.shuffle(data)\n",
        "validation_scores = []\n",
        "\n",
        "# select the validation data partiotion:\n",
        "for fold in range(k):\n",
        "  validation_data = data[num_validation_samples * fold:\n",
        "                         num_validation_samples * (fold + 1)]\n",
        "  # use the remainder of the data as training data:\n",
        "  training_data = np.concatenate(\n",
        "      data[:num_validation_samples * fold], \n",
        "      data[num_validation_samples * (fold + 1):])\n",
        "  \n",
        "  # create an untrained instance of the model: \n",
        "  model= get_model()\n",
        "  model.fit(training_data, ...)\n",
        "  validation_score = model.evaluate(validation_data, ...)\n",
        "  validation_scores.append(validation_score)\n",
        "\n",
        "# validation score as an average of the validation scores of the K folds:\n",
        "validation_score = np.average(validation_scores)\n",
        "\n",
        "# train the final model on all non-test data available:\n",
        "model = get_model()\n",
        "model.fit(data, ...)\n",
        "test_score = model.evaluate(test_data, ...) \n",
        "  "
      ],
      "metadata": {
        "id": "XoE2HngC77iy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Iterated K-fold validation with shuffling"
      ],
      "metadata": {
        "id": "pxXyC4d6_n4a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# To evaluate the model with littlde data available as precisely as possible.\n",
        "# Apply K-fold validation multiple times, shuffling the data every time \n",
        "# before splitting  i K ways. \n",
        "# The final score is the average of the scores obtained at each run of K-fold validation.\n",
        "# We have P * K model trainings and evaluations (P is the number of iterations) "
      ],
      "metadata": {
        "id": "K3fFNU3I_swB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}